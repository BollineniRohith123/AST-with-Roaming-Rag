"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ViolationOfExpectationsChain = void 0;
const messages_1 = require("@langchain/core/messages");
const output_parsers_1 = require("@langchain/core/output_parsers");
const openai_functions_js_1 = require("../../../output_parsers/openai_functions.cjs");
const base_js_1 = require("../../../chains/base.cjs");
const types_js_1 = require("./types.cjs");
const violation_of_expectations_prompt_js_1 = require("./violation_of_expectations_prompt.cjs");
/**
 * Chain that generates key insights/facts of a user based on a
 * a chat conversation with an AI.
 */
class ViolationOfExpectationsChain extends base_js_1.BaseChain {
    static lc_name() {
        return "ViolationOfExpectationsChain";
    }
    _chainType() {
        return "violation_of_expectation_chain";
    }
    get inputKeys() {
        return [this.chatHistoryKey];
    }
    get outputKeys() {
        return [this.thoughtsKey];
    }
    constructor(fields) {
        super(fields);
        Object.defineProperty(this, "chatHistoryKey", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "chat_history"
        });
        Object.defineProperty(this, "thoughtsKey", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "thoughts"
        });
        Object.defineProperty(this, "retriever", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "llm", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "jsonOutputParser", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "stringOutputParser", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.retriever = fields.retriever;
        this.llm = fields.llm;
        this.jsonOutputParser = new openai_functions_js_1.JsonOutputFunctionsParser();
        this.stringOutputParser = new output_parsers_1.StringOutputParser();
    }
    getChatHistoryString(chatHistory) {
        return chatHistory
            .map((chatMessage) => {
            if (chatMessage._getType() === "human") {
                return `Human: ${chatMessage.content}`;
            }
            else if (chatMessage._getType() === "ai") {
                return `AI: ${chatMessage.content}`;
            }
            else {
                return `${chatMessage.content}`;
            }
        })
            .join("\n");
    }
    removeDuplicateStrings(strings) {
        return [...new Set(strings)];
    }
    /**
     * This method breaks down the chat history into chunks of messages.
     * Each chunk consists of a sequence of messages ending with an AI message and the subsequent user response, if any.
     *
     * @param {BaseMessage[]} chatHistory - The chat history to be chunked.
     *
     * @returns {MessageChunkResult[]} An array of message chunks. Each chunk includes a sequence of messages and the subsequent user response.
     *
     * @description
     * The method iterates over the chat history and pushes each message into a temporary array.
     * When it encounters an AI message, it checks for a subsequent user message.
     * If a user message is found, it is considered as the user response to the AI message.
     * If no user message is found after the AI message, the user response is undefined.
     * The method then pushes the chunk (sequence of messages and user response) into the result array.
     * This process continues until all messages in the chat history have been processed.
     */
    chunkMessagesByAIResponse(chatHistory) {
        const newArray = [];
        const tempArray = [];
        chatHistory.forEach((item, index) => {
            tempArray.push(item);
            if (item._getType() === "ai") {
                let userResponse = chatHistory[index + 1];
                if (!userResponse || userResponse._getType() !== "human") {
                    userResponse = undefined;
                }
                newArray.push({
                    chunkedMessages: tempArray,
                    userResponse: userResponse
                        ? new messages_1.HumanMessage(userResponse)
                        : undefined,
                });
            }
        });
        return newArray;
    }
    /**
     * This method processes a chat history to generate insights about the user.
     *
     * @param {ChainValues} values - The input values for the chain. It should contain a key for chat history.
     * @param {CallbackManagerForChainRun} [runManager] - Optional callback manager for the chain run.
     *
     * @returns {Promise<ChainValues>} A promise that resolves to a list of insights about the user.
     *
     * @throws {Error} If the chat history key is not found in the input values or if the chat history is not an array of BaseMessages.
     *
     * @description
     * The method performs the following steps:
     * 1. Checks if the chat history key is present in the input values and if the chat history is an array of BaseMessages.
     * 2. Breaks the chat history into chunks of messages.
     * 3. For each chunk, it generates an initial prediction for the user's next message.
     * 4. For each prediction, it generates insights and prediction violations, and regenerates the prediction based on the violations.
     * 5. For each set of messages, it generates a fact/insight about the user.
     * The method returns a list of these insights.
     */
    async _call(values, runManager) {
        if (!(this.chatHistoryKey in values)) {
            throw new Error(`Chat history key ${this.chatHistoryKey} not found`);
        }
        const 